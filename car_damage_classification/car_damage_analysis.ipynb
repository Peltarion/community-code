{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation using Sidekick\n",
    "In this notebook you will learn how to use the Deployment API of the Peltarion platform via Sidekick to get predictions on samples and evaluate the performance of the deployed model in more detail.\n",
    "\n",
    "Note: This notebook requires installation of Sidekick. To install the package within the notebook, run the following code:\n",
    "\n",
    "`\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/Peltarion/sidekick#egg=sidekick\n",
    "`\n",
    "\n",
    "For more information about Sidekick, see:\n",
    "https://github.com/Peltarion/sidekick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import itertools\n",
    "import resource\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import sidekick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = '/Users/joakim/Downloads/preprocessed.zip'\n",
    "extract_path = '/Users/joakim/Downloads'\n",
    "\n",
    "dataset_path = os.path.join(extract_path, 'preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
    "zip_ref.extractall(extract_path)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_url = 'https:...'\n",
    "deploy_token = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_score(pred):\n",
    "    max_key = 'None'\n",
    "    max_score = 0\n",
    "    dict = pred['class'].items()\n",
    "    for key,score in dict:\n",
    "        if score >= max_score:        \n",
    "            max_key = key\n",
    "            max_score = score\n",
    "    return (max_key, max_score)\n",
    "\n",
    "def get_image(path):\n",
    "    im = Image.open(os.path.join(dataset_path, path))\n",
    "    new_im = im.copy()\n",
    "    new_im.format = 'jpeg'\n",
    "    im.close()\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting single  predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = sidekick.Deployment(\n",
    "    # Enter URL and token\n",
    "    url=deploy_url,\n",
    "    token=deploy_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = os.path.join(dataset_path, 'index.csv')\n",
    "df = pd.read_csv(index_path)\n",
    "df = df.sample(frac=1, random_state=2323)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict damage for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path_list = iter(list(df['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = next(im_path_list)\n",
    "im = Image.open(os.path.join(dataset_path, im_path))\n",
    "display(im)\n",
    "pred = client.predict(image=im)\n",
    "print(get_max_score(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict damage for multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rows = df.head()\n",
    "for i, row in first_rows.iterrows():\n",
    "    img = Image.open(os.path.join(dataset_path, row['image']))\n",
    "    display(img)\n",
    "    pred = client.predict(image=img)\n",
    "    print('Ground truth: {}\\nPrediction: {}'.format(row['class'], pred['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions (batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out training data\n",
    "The predictions on the evaluation subset will be used in the analysis of the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "eval_df = df[df['subset']=='V'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['image_url'] = eval_df['image']\n",
    "eval_df['image'] = eval_df['image'].apply(lambda path: get_image(path))\n",
    "predictions = client.predict_lazy(eval_df.to_dict('record'))\n",
    "eval_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This may take several minutes...\n",
    "preds = [p for p in predictions]\n",
    "eval_df['pred'] = [p['class'] for p in preds]\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = eval_df['pred']\n",
    "max_keys = []\n",
    "max_scores = []\n",
    "\n",
    "for i in dicts:\n",
    "    max_val = max(i.items(), key=lambda k: k[1])     \n",
    "    max_keys.append(max_val[0])\n",
    "    max_scores.append(max_val[1])\n",
    "eval_df['pred_class'] = max_keys\n",
    "eval_df['pred_score'] = max_scores\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df = eval_df.loc[eval_df['class'] != eval_df['pred_class']]\n",
    "wrong_df = wrong_df.sort_values(by=['pred_score'], ascending=False)\n",
    "first_rows = wrong_df.head(10)\n",
    "for i, row in first_rows.iterrows():\n",
    "    display(row['image'])\n",
    "    print('Ground truth: {}, Prediction: {}, Score: {}'.format(row['class'], row['pred_class'], row['pred_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
